"""
NiksES Malware Detection Rules

Rules for detecting malware indicators in email attachments and content.
"""

import re
from typing import Optional, List

from app.models.email import ParsedEmail
from app.models.enrichment import EnrichmentResults, ThreatIntelVerdict
from app.models.detection import RiskLevel
from app.utils.constants import DANGEROUS_EXTENSIONS

from .base import DetectionRule, RuleMatch, register_rule


@register_rule
class MaliciousAttachmentRule(DetectionRule):
    """Detect attachments flagged as malicious by threat intelligence."""
    
    rule_id = "MAL-001"
    name = "Malicious Attachment Detected"
    description = "Attachment is flagged as malware by threat intelligence sources"
    category = "malware"
    severity = RiskLevel.CRITICAL
    mitre_technique = "T1566.001"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        if not enrichment or not enrichment.attachments:
            return None
        
        malicious = []
        for att_enrichment in enrichment.attachments:
            if att_enrichment.final_verdict == ThreatIntelVerdict.MALICIOUS:
                malicious.append({
                    'filename': att_enrichment.filename,
                    'sha256': att_enrichment.sha256,
                    'vt_positives': att_enrichment.virustotal_positives,
                    'threat_names': att_enrichment.virustotal_threat_names[:5],
                })
        
        if malicious:
            evidence = [f"Found {len(malicious)} malicious attachment(s):"]
            for att in malicious:
                evidence.append(f"  - {att['filename']}")
                if att.get('vt_positives'):
                    evidence.append(f"    VirusTotal: {att['vt_positives']} detections")
                if att.get('threat_names'):
                    evidence.append(f"    Threats: {', '.join(att['threat_names'][:3])}")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'malicious_attachment',
                    **att
                } for att in malicious],
            )
        
        return None


@register_rule
class ExecutableAttachmentRule(DetectionRule):
    """Detect executable file attachments."""
    
    rule_id = "MAL-002"
    name = "Executable Attachment"
    description = "Email contains executable file attachment"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1204.002"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        executables = []
        
        for attachment in email.attachments:
            if attachment.is_executable:
                executables.append({
                    'filename': attachment.filename,
                    'extension': attachment.extension,
                    'size': attachment.size_bytes,
                    'sha256': attachment.sha256,
                })
        
        if executables:
            evidence = [
                f"Found {len(executables)} executable attachment(s):",
                "Executable files can run malicious code",
            ]
            for exe in executables:
                evidence.append(f"  - {exe['filename']} ({exe['extension']})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'executable_attachment',
                    **exe
                } for exe in executables],
            )
        
        return None


@register_rule
class MacroEnabledOfficeRule(DetectionRule):
    """Detect macro-enabled Office documents."""
    
    rule_id = "MAL-003"
    name = "Macro-Enabled Office Document"
    description = "Email contains macro-enabled Office document (docm, xlsm, etc.)"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1566.001"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        macro_files = []
        
        for attachment in email.attachments:
            if attachment.is_office_with_macros:
                macro_files.append({
                    'filename': attachment.filename,
                    'extension': attachment.extension,
                    'size': attachment.size_bytes,
                    'sha256': attachment.sha256,
                })
        
        if macro_files:
            evidence = [
                f"Found {len(macro_files)} macro-enabled Office document(s):",
                "Macros can contain malicious VBA code",
            ]
            for mf in macro_files:
                evidence.append(f"  - {mf['filename']}")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'macro_enabled_office',
                    **mf
                } for mf in macro_files],
            )
        
        return None


@register_rule
class ScriptAttachmentRule(DetectionRule):
    """Detect script file attachments."""
    
    rule_id = "MAL-004"
    name = "Script Attachment"
    description = "Email contains script file attachment (.js, .vbs, .ps1, etc.)"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1059"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        scripts = []
        
        for attachment in email.attachments:
            if attachment.is_script:
                scripts.append({
                    'filename': attachment.filename,
                    'extension': attachment.extension,
                    'sha256': attachment.sha256,
                })
        
        if scripts:
            evidence = [
                f"Found {len(scripts)} script attachment(s):",
                "Script files can execute malicious code",
            ]
            for script in scripts:
                evidence.append(f"  - {script['filename']} ({script['extension']})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'script_attachment',
                    **script
                } for script in scripts],
            )
        
        return None


@register_rule
class ArchiveAttachmentRule(DetectionRule):
    """Detect archive file attachments."""
    
    rule_id = "MAL-005"
    name = "Archive Attachment"
    description = "Email contains archive file attachment (.zip, .rar, .7z, etc.)"
    category = "malware"
    severity = RiskLevel.LOW
    mitre_technique = "T1566.001"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        archives = []
        
        for attachment in email.attachments:
            if attachment.is_archive:
                archives.append({
                    'filename': attachment.filename,
                    'extension': attachment.extension,
                    'size': attachment.size_bytes,
                    'sha256': attachment.sha256,
                })
        
        if archives:
            # Lower severity for single small archive
            severity = RiskLevel.MEDIUM if len(archives) > 1 else RiskLevel.LOW
            
            evidence = [
                f"Found {len(archives)} archive attachment(s):",
                "Archives can contain malicious files",
            ]
            for arch in archives:
                evidence.append(f"  - {arch['filename']} ({arch['size']} bytes)")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'archive_attachment',
                    **arch
                } for arch in archives],
                severity_override=severity,
            )
        
        return None


@register_rule
class DoubleExtensionRule(DetectionRule):
    """Detect files with double extensions (e.g., invoice.pdf.exe)."""
    
    rule_id = "MAL-006"
    name = "Double Extension Detected"
    description = "Attachment has double extension, possibly hiding true file type"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1036.007"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        double_ext = []
        
        # All dangerous extensions
        dangerous_exts = set()
        for ext_list in DANGEROUS_EXTENSIONS.values():
            dangerous_exts.update(ext_list)
        
        for attachment in email.attachments:
            filename = attachment.filename.lower()
            
            # Check for patterns like .pdf.exe, .doc.js
            parts = filename.rsplit('.', 2)
            if len(parts) >= 3:
                # filename.ext1.ext2
                ext2 = '.' + parts[-1]
                ext1 = '.' + parts[-2]
                
                # If final extension is dangerous
                if ext2 in dangerous_exts:
                    double_ext.append({
                        'filename': attachment.filename,
                        'apparent_ext': ext1,
                        'actual_ext': ext2,
                    })
        
        if double_ext:
            evidence = [
                "Detected file(s) with double extensions:",
                "This technique hides the true executable nature of files",
            ]
            for de in double_ext:
                evidence.append(f"  - {de['filename']} (appears as {de['apparent_ext']}, actually {de['actual_ext']})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'double_extension',
                    **de
                } for de in double_ext],
                severity_override=RiskLevel.CRITICAL,
            )
        
        return None


@register_rule
class MismatchedMIMETypeRule(DetectionRule):
    """Detect attachments where MIME type doesn't match extension."""
    
    rule_id = "MAL-007"
    name = "MIME Type Mismatch"
    description = "Attachment's declared MIME type doesn't match file extension or magic bytes"
    category = "malware"
    severity = RiskLevel.MEDIUM
    mitre_technique = "T1036"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        mismatches = []
        
        # Expected MIME types for extensions
        expected_mimes = {
            '.pdf': ['application/pdf'],
            '.doc': ['application/msword'],
            '.docx': ['application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
            '.xls': ['application/vnd.ms-excel'],
            '.xlsx': ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'],
            '.jpg': ['image/jpeg'],
            '.png': ['image/png'],
            '.gif': ['image/gif'],
            '.zip': ['application/zip', 'application/x-zip-compressed'],
        }
        
        for attachment in email.attachments:
            ext = attachment.extension.lower()
            mime = attachment.content_type.lower() if attachment.content_type else ''
            
            if ext in expected_mimes:
                if mime and not any(exp in mime for exp in expected_mimes[ext]):
                    mismatches.append({
                        'filename': attachment.filename,
                        'extension': ext,
                        'declared_mime': attachment.content_type,
                        'expected_mimes': expected_mimes[ext],
                    })
        
        if mismatches:
            evidence = ["MIME type mismatch detected:"]
            for mm in mismatches:
                evidence.append(f"  - {mm['filename']}: {mm['declared_mime']} (expected {mm['expected_mimes'][0]})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'mime_mismatch',
                    **mm
                } for mm in mismatches],
            )
        
        return None


@register_rule
class MaliciousQRCodeRule(DetectionRule):
    """Detect malicious URLs in QR codes."""
    
    rule_id = "MAL-008"
    name = "Malicious QR Code"
    description = "QR code in attachment contains malicious URL"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1566.001"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        if not email.qr_codes:
            return None
        
        # Check if any QR code URLs are malicious
        malicious_qr = []
        
        for qr in email.qr_codes:
            if qr.data_type == 'url' and qr.extracted_url:
                # Check against enrichment if available
                if enrichment and enrichment.urls:
                    for url_enrich in enrichment.urls:
                        if url_enrich.url == qr.extracted_url:
                            if url_enrich.final_verdict in [ThreatIntelVerdict.MALICIOUS, ThreatIntelVerdict.SUSPICIOUS]:
                                malicious_qr.append({
                                    'source': qr.source_attachment,
                                    'url': qr.extracted_url,
                                    'verdict': url_enrich.final_verdict.value,
                                })
                            break
        
        if malicious_qr:
            evidence = ["Malicious URL(s) found in QR code(s):"]
            for qr in malicious_qr:
                evidence.append(f"  - {qr['url']} (in {qr['source']})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'malicious_qr_code',
                    **qr
                } for qr in malicious_qr],
            )
        
        return None


@register_rule
class QRCodeURLRule(DetectionRule):
    """Detect QR codes containing URLs (informational)."""
    
    rule_id = "MAL-009"
    name = "QR Code Contains URL"
    description = "QR code in attachment contains a URL that should be reviewed"
    category = "malware"
    severity = RiskLevel.INFORMATIONAL
    mitre_technique = "T1566.001"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        if not email.qr_codes:
            return None
        
        url_qr_codes = []
        
        for qr in email.qr_codes:
            if qr.data_type == 'url' and qr.extracted_url:
                url_qr_codes.append({
                    'source': qr.source_attachment,
                    'url': qr.extracted_url,
                })
        
        if url_qr_codes:
            evidence = [f"Found {len(url_qr_codes)} QR code(s) containing URLs:"]
            for qr in url_qr_codes:
                evidence.append(f"  - {qr['url'][:80]} (in {qr['source']})")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'qr_code_url',
                    **qr
                } for qr in url_qr_codes],
            )
        
        return None


@register_rule
class LNKAttachmentRule(DetectionRule):
    """Detect Windows shortcut (.lnk) file attachments."""
    
    rule_id = "MAL-010"
    name = "LNK Shortcut Attachment"
    description = "Email contains Windows shortcut file which can execute commands"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1204.002"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        lnk_files = []
        
        for attachment in email.attachments:
            if attachment.extension.lower() == '.lnk':
                lnk_files.append({
                    'filename': attachment.filename,
                    'sha256': attachment.sha256,
                })
        
        if lnk_files:
            evidence = [
                "Windows shortcut (.lnk) file(s) detected:",
                "LNK files can execute arbitrary commands",
            ]
            for lnk in lnk_files:
                evidence.append(f"  - {lnk['filename']}")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'lnk_attachment',
                    **lnk
                } for lnk in lnk_files],
            )
        
        return None


@register_rule
class ISOIMGAttachmentRule(DetectionRule):
    """Detect disk image attachments (.iso, .img)."""
    
    rule_id = "MAL-011"
    name = "Disk Image Attachment"
    description = "Email contains disk image file (.iso, .img) which can bypass security"
    category = "malware"
    severity = RiskLevel.HIGH
    mitre_technique = "T1553.005"
    
    async def evaluate(
        self,
        email: ParsedEmail,
        enrichment: Optional[EnrichmentResults] = None
    ) -> Optional[RuleMatch]:
        disk_images = []
        
        for attachment in email.attachments:
            ext = attachment.extension.lower()
            if ext in ['.iso', '.img', '.vhd', '.vhdx']:
                disk_images.append({
                    'filename': attachment.filename,
                    'extension': ext,
                    'size': attachment.size_bytes,
                    'sha256': attachment.sha256,
                })
        
        if disk_images:
            evidence = [
                "Disk image file(s) detected:",
                "Disk images can contain malware that bypasses Mark-of-the-Web",
            ]
            for img in disk_images:
                evidence.append(f"  - {img['filename']} ({img['size']} bytes)")
            
            return self.create_match(
                evidence=evidence,
                indicators=[{
                    'type': 'disk_image_attachment',
                    **img
                } for img in disk_images],
            )
        
        return None
